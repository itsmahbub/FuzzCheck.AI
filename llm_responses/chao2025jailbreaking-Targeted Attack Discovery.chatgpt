```json
{
  "value": "High",
  "why": "The PAIR algorithm is explicitly designed to steer its search toward attacker-specified objectives: each run is given an objective O (a specific harmful behavior or piece of content), the attacker LLM is initialized with that objective and tasked to generate candidate prompts to elicit that particular output from the target, and the JUDGE function evaluates whether the target's response satisfies that objective. Experiments operate over a benchmark of 100 specific behaviors (JBB-Behaviors) and report per-behavior jailbreak percentages and queries-per-success, demonstrating that PAIR pursues and measures success on predefined target outcomes rather than performing untargeted fault discovery.",
  "evidence": "Section II (Preliminaries), p.24: \"To this end, throughout the paper we assume that each jailbreak is characterized by an objective O, which describes the toxic content that the attacker seeks to elicit from the target (e.g., 'tell me how to build a bomb'). The objective O informs the generation and evaluation of prompts...\"; Section III-B (Algorithm 1), p.25: \"Input: Number of iterations K, attack objective O\" and \"Initialize: system prompt of A with O\"; Section III-A (Attack generation), p.24: \"We design targeted, yet flexible system prompts which direct the attacker A to generate a candidate prompt P that jailbreak the target model.\"; Section IV (Experiments), p.26: \"When red teaming LLMs, the objective is to discover prompts that elicit responses from a targeted LLM which contain the content requested in each behavior from JBB-Behaviors, as evaluated by the JUDGE function.\""
}
```